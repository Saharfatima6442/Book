---
sidebar_position: 15
---

# Technical Jargon and Definitions

## A

**Actuator**: A mechanical device that converts energy (usually electrical) into physical motion. In humanoid robots, actuators control joint movement.

**Admittance Control**: A control strategy that relates force inputs to position outputs, making robots compliant to external forces.

**AI Planning**: The process of determining a sequence of actions to achieve a goal, considering constraints and uncertainty.

**Artificial Intelligence (AI)**: The simulation of human intelligence processes by machines, especially computer systems, including learning, reasoning, and self-correction.

## B

**Behavior Tree**: A hierarchical tree structure used in robotics and AI to create complex behaviors from simple tasks.

**Bipedal Locomotion**: The act of walking on two legs, which is mechanically challenging due to the need for dynamic balance.

**Bounding Box**: A rectangular box that encloses an object in 2D or 3D space, used for object detection and tracking.

## C

**Center of Mass (CoM)**: The point where the total mass of a body may be considered to be concentrated for the purpose of analyzing motion.

**Computer Vision**: A field of AI that trains computers to interpret and understand the visual world using digital images and deep learning models.

**Convolutional Neural Network (CNN)**: A class of deep neural networks most commonly applied to analyzing visual imagery.

**Conversational AI**: AI systems that can understand, process, and respond to human language in a natural, conversational manner.

**Control Theory**: An interdisciplinary branch of engineering and mathematics that deals with the behavior of dynamical systems with inputs and how their behavior is modified by feedback.

**Covariance Matrix**: A mathematical concept used in robotics to represent uncertainty in sensor measurements and state estimates.

## D

**Deep Learning**: A subset of machine learning that uses neural networks with many layers to model complex patterns in data.

**Depth Camera**: A camera that captures distance information for every pixel, creating a 3D representation of the scene.

**Differential Drive**: A type of wheeled robot locomotion system where each wheel is independently controlled.

**Digital Twin**: A virtual representation of a physical system that can be used for simulation, testing, and optimization.

**Domain Randomization**: A technique in simulation where environment parameters are randomly varied to improve sim-to-real transfer.

## E

**Embodied AI**: Artificial intelligence that interacts with the physical world through a physical body, as opposed to purely digital systems.

**End-Effector**: The device at the end of a robotic arm that interacts with the environment, such as a gripper or tool.

**Episodic Memory**: A type of memory system that stores specific events or episodes, important for contextual robot behavior.

**Ethical AI**: The development and deployment of AI systems that are fair, transparent, and aligned with human values.

## F

**Force Control**: A control strategy that directly controls the forces applied by a robot, important for safe human-robot interaction.

**Forward Kinematics**: The process of determining the position and orientation of a robot's end-effector based on joint angles.

**Fused Perception**: The integration of information from multiple sensors to create a more accurate and reliable understanding of the environment.

## G

**Gazebo**: A 3D simulation environment for robotics that provides realistic physics and sensor simulation.

**General Artificial Intelligence (AGI)**: Hypothetical AI that possesses the general intelligence of a human being and can apply that intelligence to solve any problem.

**Geometric Transformations**: Mathematical operations used to represent position, orientation, and movement in 3D space.

**Gripper**: A device used to grasp and manipulate objects, typically at the end of a robotic arm.

**GPU Acceleration**: The use of graphics processing units to accelerate computational tasks, especially important for AI inference.

## H

**Heuristic**: A problem-solving approach that uses practical methods or rules of thumb rather than guaranteed optimal solutions.

**Human-Robot Interaction (HRI)**: The study of interactions between humans and robots, focusing on design and implementation of robots for human use.

**Homing**: The process of determining the absolute position of robot joints by moving to known reference positions.

## I

**Inertial Measurement Unit (IMU)**: A device that measures and reports a body's specific force, angular rate, and sometimes the magnetic field surrounding the body.

**Inverse Kinematics**: The mathematical process of determining joint angles required to achieve a desired end-effector position and orientation.

**Isaac Sim**: NVIDIA's simulation application for developing and testing AI-based robotics applications.

**Isaac ROS**: NVIDIA's collection of GPU-accelerated ROS 2 packages for perception, navigation, and manipulation.

## J

**Joint Space**: The space defined by the joint angles of a robot, as opposed to Cartesian space.

**Jacobian Matrix**: A matrix of partial derivatives that describes the relationship between joint velocities and end-effector velocities.

## K

**Kinematics**: The study of motion without considering the forces that cause the motion.

**Kinesthetic Teaching**: A method of programming robots by physically guiding them through motions.

## L

**LIDAR (Light Detection and Ranging)**: A remote sensing method that uses light in the form of a pulsed laser to measure distances.

**Linear Inverted Pendulum Model (LIPM)**: A simplified model used in humanoid robotics to represent the dynamics of bipedal walking.

**Localization**: The process of determining a robot's position and orientation within an environment.

**LoCoBot**: A low-cost mobile manipulator platform designed for research and education.

## M

**Machine Learning**: A type of AI that allows software applications to become more accurate at predicting outcomes without being explicitly programmed to do so.

**Manipulation**: The ability of a robot to physically interact with objects in its environment.

**Markov Decision Process (MDP)**: A mathematical framework for modeling decision-making in situations where outcomes are partly random and partly under the control of a decision maker.

**Motion Planning**: The process of determining a collision-free path for a robot from a start configuration to a goal configuration.

**Multimodal AI**: AI systems that can process and integrate information from multiple sensory modalities (e.g., vision, audio, touch).

## N

**Navigation**: The ability of a robot to move through an environment from one location to another.

**Neural Network**: A series of algorithms that endeavors to recognize underlying relationships in a set of data through a process that mimics how the human brain operates.

**Non-Holonomic Constraint**: A constraint on a system that cannot be integrated to give a constraint on the coordinates alone.

## O

**Occupancy Grid**: A probabilistic 2D or 3D representation of space that indicates the likelihood of obstacles at different locations.

**Operational Space**: The space in which a robot's end-effector operates, typically Cartesian space.

**Omnidirectional Drive**: A type of robot locomotion that allows movement in any direction without changing orientation.

## P

**Partially Observable Markov Decision Process (POMDP)**: A generalization of MDP that models uncertainty in state observations.

**Path Planning**: The process of determining a geometric path from a start point to a goal point.

**Perception**: The ability of a robot to interpret sensory information to understand its environment.

**Physical AI**: AI systems that operate in the physical world, interacting with real objects and environments.

**Point Cloud**: A set of data points in space, typically representing the external surface of an object.

**Pose**: The position and orientation of an object in 3D space.

**Proxemics**: The study of the spatial relationships between people and their use of space in communication.

## R

**Real-Time Control**: Control systems that must respond to inputs within strict timing constraints.

**Reinforcement Learning**: A type of machine learning where an agent learns to make decisions by taking actions in an environment to maximize cumulative reward.

**Robot Operating System (ROS)**: A flexible framework for writing robot software that provides services for hardware abstraction, device drivers, and message passing.

**ROS 2**: The second generation of the Robot Operating System with improved security, real-time capabilities, and production readiness.

**RRT (Rapidly-exploring Random Tree)**: A motion planning algorithm used for path planning in robotics.

## S

**Sensor Fusion**: The process of combining data from multiple sensors to achieve better accuracy and reliability than could be achieved by using a single sensor.

**Simultaneous Localization and Mapping (SLAM)**: The computational problem of constructing or updating a map of an unknown environment while simultaneously keeping track of an agent's location within it.

**Singularity**: A configuration in which a robot loses one or more degrees of freedom due to alignment of joint axes.

**Social Navigation**: Navigation that considers social norms and human behavior in path planning.

**State Estimation**: The process of estimating the internal state of a system from noisy measurements.

**Stereo Vision**: A method of determining depth by comparing two images taken from slightly different positions.

**Supervised Learning**: A type of machine learning where the model is trained on labeled data.

## T

**Task Planning**: The process of determining a sequence of high-level actions to achieve a goal.

**Teaching Pendant**: A handheld device used to program and control industrial robots.

**Trajectory**: A time-parameterized path that specifies position, velocity, and acceleration at each point in time.

**Transform**: A mathematical operation that converts coordinates from one reference frame to another.

## U

**Unstructured Environment**: An environment that lacks predefined organization or predictable patterns, unlike structured environments like factories.

**Unsupervised Learning**: A type of machine learning that learns patterns from unlabeled data.

## V

**Velocity Control**: Control of the rate of change of position of a robot or its components.

**Vision-Language-Action (VLA)**: Systems that integrate visual perception, language understanding, and physical action.

**Visual Servoing**: Control of robot motion using visual feedback.

## W

**Whole-Body Control**: Control of all degrees of freedom of a robot simultaneously, considering all constraints.

**Workspace**: The volume of space that a robot's end-effector can reach.

## Z

**Zero Moment Point (ZMP)**: A concept used in bipedal robotics to determine the stability of walking robots by calculating where the ground reaction force would need to act to maintain balance.